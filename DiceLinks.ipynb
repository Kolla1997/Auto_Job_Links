{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf268a3-f086-48c8-a0bd-5907b6a2d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â„¹ï¸  No new jobs found. All scraped jobs already exist in the database.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "DICE_URL = \"https://www.dice.com/jobs?filters.postedDate=ONE&filters.employmentType=CONTRACTS%7CTHIRD_PARTY&countryCode=US&latitude=38.7945952&location=United+States&locationPrecision=Country&longitude=-106.5348379&q=Golang\"\n",
    "TELEGRAM_BOT_TOKEN = \"8503178182:AAG2euQgRP2DkaDDPD_rrM9tLyZynshtHn8\"\n",
    "CHAT_ID = \"-1003628736585\"\n",
    "EXCEL_FILE = 'dice_jobs_list.xlsx'\n",
    "\n",
    "TELEGRAM_URL = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
    "\n",
    "def process_job_links(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    jobs_data = []\n",
    "\n",
    "    job_links = soup.find_all(\n",
    "        \"a\",\n",
    "        attrs={\"data-testid\": \"job-search-job-detail-link\"}\n",
    "    )\n",
    "\n",
    "    for job in job_links:\n",
    "        title = job.get_text(strip=True)\n",
    "        url = job.get(\"href\")\n",
    "\n",
    "        location_tag = job.find_next(\n",
    "            \"p\", class_=\"text-sm font-normal text-zinc-600\"\n",
    "        )\n",
    "        location = location_tag.get_text(strip=True) if location_tag else None\n",
    "\n",
    "        employment_tag = job.find_next(\"p\", id=\"employmentType-label\")\n",
    "        employment_type = (\n",
    "            employment_tag.get_text(strip=True) if employment_tag else None\n",
    "        )\n",
    "\n",
    "        salary_tag = job.find_next(\"p\", id=\"salary-label\")\n",
    "        salary = salary_tag.get_text(strip=True) if salary_tag else None\n",
    "\n",
    "        company_tag = job.find_next(\n",
    "            \"p\", class_=\"mb-0 line-clamp-2 text-sm sm:line-clamp-1\"\n",
    "        )\n",
    "        company = company_tag.get_text(strip=True) if company_tag else None\n",
    "        keywords = [\"golang\", \"go developer\", \"go engineer\", \"go\", \"application support engineer\", \"backend\"]\n",
    "        \n",
    "        if any(k in title.lower() for k in keywords):\n",
    "            jobs_data.append({\n",
    "                \"Title\": title,\n",
    "                \"URL\": url,\n",
    "                \"Location\": location,\n",
    "                \"Employment_Type\": employment_type,\n",
    "                \"Salary\": salary,\n",
    "                \"Company\": company\n",
    "            })\n",
    "\n",
    "    return jobs_data\n",
    "\n",
    "def fetch_all_links(dice_url):\n",
    "    page_num = 0\n",
    "    all_jobs = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(dice_url, params={\"page\": page_num}, timeout=10)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "\n",
    "        page_jobs = process_job_links(response.text)\n",
    "\n",
    "        if not page_jobs:\n",
    "            break\n",
    "\n",
    "        all_jobs.extend(page_jobs)\n",
    "        page_num += 1\n",
    "\n",
    "    return pd.DataFrame(all_jobs)\n",
    "\n",
    "def load_existing_jobs():\n",
    "    \"\"\"Load existing jobs from Excel file\"\"\"\n",
    "    if os.path.exists(EXCEL_FILE):\n",
    "        try:\n",
    "            df_existing = pd.read_excel(EXCEL_FILE, engine='openpyxl')\n",
    "            logging.info(f\"Loaded {len(df_existing)} existing jobs from {EXCEL_FILE}\")\n",
    "            return df_existing\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading Excel file: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        logging.info(\"No existing Excel file found. Will create new one.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_to_excel(df_new, df_existing):\n",
    "    \"\"\"Save or append jobs to Excel file\"\"\"\n",
    "    try:\n",
    "        if df_existing.empty:\n",
    "            df_new.to_excel(EXCEL_FILE, index=False, engine='openpyxl')\n",
    "            logging.info(f\"Created new Excel file: {EXCEL_FILE}\")\n",
    "        else:\n",
    "            df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "            # Remove duplicates based on URL\n",
    "            df_combined = df_combined.drop_duplicates(subset=['URL'], keep='first')\n",
    "            df_combined.to_excel(EXCEL_FILE, index=False, engine='openpyxl')\n",
    "            logging.info(f\"Updated Excel file with {len(df_new)} new jobs\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving to Excel: {e}\")\n",
    "        return False\n",
    "\n",
    "def flt_exsis_links(df_scraped):\n",
    "    \"\"\"Filter out existing jobs and return only new ones\"\"\"\n",
    "    df_existing = load_existing_jobs()\n",
    "    \n",
    "    if df_existing.empty:\n",
    "        logging.info(\"No existing data. All scraped jobs are new.\")\n",
    "        return df_scraped, df_existing\n",
    "    existing_urls = set(df_existing['URL'].tolist())\n",
    "    df_new = df_scraped[~df_scraped['URL'].isin(existing_urls)]\n",
    "    \n",
    "    logging.info(f\"Found {len(df_new)} new jobs out of {len(df_scraped)} scraped jobs\")\n",
    "    return df_new, df_existing\n",
    "\n",
    "def end_msg_jobs_telegram(new_job_count):\n",
    "    now = datetime.now().strftime(\"%B %d, %Y -- %I:%M %p\")\n",
    "    separator = \"-\" * 55\n",
    "    payload = {\n",
    "        \"chat_id\": CHAT_ID,\n",
    "        \"text\": f\"\"\"\n",
    "            â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "            â•‘   DICE SCRAPER COMPLETED âœ…                 â•‘\n",
    "            â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "            â•‘ â° {now}                                    â•‘\n",
    "            â•‘ ğŸ†• New Jobs: {str(new_job_count)}           â•‘\n",
    "            â•‘ ğŸ“Š Status: SUCCESS                          â•‘\n",
    "            â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                \"\"\",\n",
    "        \"parse_mode\": \"Markdown\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(TELEGRAM_URL, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            logging.info(\"Sent completion message to Telegram\")\n",
    "        else:\n",
    "            logging.error(f\"Failed to send completion message: {response.text}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error sending completion message: {e}\")\n",
    "    \n",
    "\n",
    "def send_jobs_to_telegram(df):\n",
    "    for _, row in df.iterrows():\n",
    "        message = (\n",
    "            f\"*{row['Title']}*\\n\"\n",
    "            f\"ğŸ¢ {row['Company'] or 'Unknown Company'}\\n\"\n",
    "            f\"ğŸ“ {row['Location'] or 'Location not listed'}\\n\"\n",
    "            f\"ğŸ“ Employment: {row['Employment_Type'] or 'N/A'}\\n\"\n",
    "            f\"ğŸ’° Salary: {row['Salary'] or 'N/A'}\\n\"\n",
    "            f\"ğŸ”— [Apply here]({row['URL']})\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"chat_id\": CHAT_ID,\n",
    "            \"text\": message,\n",
    "            \"parse_mode\": \"Markdown\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(TELEGRAM_URL, json=payload)\n",
    "            if response.status_code == 200:\n",
    "                logging.info(f\"Sent job to Telegram: {row['Title']}\")\n",
    "            else:\n",
    "                logging.error(f\"Failed to send job: {response.text}\")\n",
    "            time.sleep(1)  # Avoid rate limits\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending to Telegram: {e}\")\n",
    "    \n",
    "\n",
    "def main():\n",
    "    df_scraped = fetch_all_links(DICE_URL)\n",
    "\n",
    "    if df_scraped.empty:\n",
    "        print(\"No jobs found during scraping.\")\n",
    "        return\n",
    "    df_new, df_existing = flt_exsis_links(df_scraped)\n",
    "    \n",
    "    if df_new.empty:\n",
    "        print(\"\\nâ„¹ï¸  No new jobs found. All scraped jobs already exist in the database.\")\n",
    "        end_msg_jobs_telegram(0)\n",
    "        return\n",
    "    if save_to_excel(df_new, df_existing):\n",
    "        print(f\"ğŸ’¾ Successfully saved to {EXCEL_FILE}\")\n",
    "    print(len(df_new))\n",
    "    send_jobs_to_telegram(df_new.sample(2))\n",
    "    end_msg_jobs_telegram(len(df_new))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13087e9a-64eb-4ea5-8f0a-3a45f64bc271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
